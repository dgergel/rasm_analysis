{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started with Dask and Running Jupyter Notebooks on the DoD Utility Servers ## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this is a modified version of this notebook: https://github.com/pangeo-data/pangeo/wiki/Getting-Started-with-Dask-on-Cheyenne# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook documents how to set up a virtual Python environment on the Department of Defense Utility Servers. In particular it covers the following:\n",
    "\n",
    "1) Install conda and create a virtual environment\n",
    "\n",
    "2) Configure Jupyter\n",
    "\n",
    "3) Launch Dask with a job scheduler\n",
    "\n",
    "4) Launch a Jupyter server for your job\n",
    "\n",
    "5) Connect to Jupyter and the Dask dashboard from your personal computer\n",
    "\n",
    "This assumes that you are already fairly comfortable using the command line, such as using a text editor. \n",
    "\n",
    "To start with, log on to the Utility Server you plan to use (AFRL, ERDC, NAVY). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing a software environment ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have logged into the Utility Server of your choice (AFRL, ERDC, Navy), download and install Miniconda. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
    "./Miniconda3-latest-Linux-x86_64.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process will take a few minutes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This contains a self-contained Python environment that we can manipulate safely without requiring the involvement of IT. It also allows you to create isolated software environments so that we can experiment in the future safely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conda create -n pangeo -c conda-forge \\\n",
    "    python=3.6 dask distributed xarray jupyterlab mpi4py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will also take a few minutes - it's a good time to get a cup of coffee. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the environment, you will need to either log out and log back in or start a new terminal for your `conda` commands to work on the command line. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activate this environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source activate pangeo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your prompt should now look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(pangeo) [gergel@viutill-0002 ~]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if you ask where your Python command lives, it should direct you to somewhere in your home directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(pangeo) [gergel@viutill-0002 ~]$ which python\n",
    "~/miniconda3/envs/pangeo/bin/python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Jupyter to use Jupyter Notebooks ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: if you only want to run python scripts on the Utility Servers, you can skip all of the following sections and just activate the python environment you created to run Python scripts. At any point in time, if you need to add a Python package, you can do so using `conda install package_name` after activating the environment on the command line. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter notebook servers include a password for security. We're going to setup a password for ourselves. First we generate the Jupyter config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jupyter notebook --generate-config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your output should look like the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Writing default config to: /u/US_HOME2/gergel/.jupyter/jupyter_notebook_config.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you open that file and search for \"password\", you'll see a line like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#c.NotebookApp.password = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The instructions in the comments of the config file tell you to generate a hashed password by entering the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from notebook.auth import passwd; passwd()\n",
    "Enter password:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can enter a password of your choice, and it will return to you a hashed password that encodes the same information, but is safe to include in a publicly accessible config file. I got the following output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Out[1]: 'sha1:30adc662b899:24963c5aae5ac22f0f433cfbe22d590dd7054db5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After exiting from Ipython, copy that string into your jupyter_notebook_config.py config file and save the config file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c.NotebookApp.password = u'sha1:69a76df803b9:99ca27341563cd85ba4e78684128e1f4ad2d8d0d'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch Dask with a script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy and paste the following text into a file and name the file dask.sh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#PBS -N dask\n",
    "#PBS -q parallel\n",
    "#PBS -A NPSCA07935YF5\n",
    "#PBS -l select=1:ncpus=32:mpiprocs=8:mem=200GB\n",
    "#PBS -l walltime=12:00:00\n",
    "#PBS -j oe\n",
    "#PBS -m abe\n",
    "\n",
    "# Qsub template for AFRL US\n",
    "# Scheduler: PBS\n",
    "\n",
    "# This writes a scheduler.json file into your home directory\n",
    "# You can then connect with the following Python code\n",
    "# >>> from dask.distributed import Client\n",
    "# >>> client = Client(scheduler_file='~/scheduler.json')\n",
    "\n",
    "export LANG=\"en_US.utf8\"\n",
    "export LANGUAGE=\"en_US.utf8\"\n",
    "export LC_ALL=\"en_US.utf8\"\n",
    "\n",
    "unset LD_LIBRARY_PATH\n",
    "source activate pangeo\n",
    "\n",
    "rm -f scheduler.json\n",
    "mpirun --np 8 dask-mpi --nthreads 4 --memory-limit 24e9 # --interface ib0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script asks for one nodes with 32 cores each. It breaks up each node into 8 MPI processes. You can tweak the numbers above if you like, but you'll have to match some constraints in the PBS directives on the top and the mpirun keywords on the bottom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit this script to run on the cluster with `qsub`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qsub dask.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you submit the job you'll get a job ID: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "116716.viutill-0003.erdc.hpc.mil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can check on the status of the job: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qstat -u $USER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When this job runs it places a `scheduler.json` file in your home directory. This contains the necessaary information to connect to this cluster from anywhere in the network. We'll do that now briefly from the login node. In the next section we'll set up a Jupyter notebook server on your allocation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: if you *don't* have a `scheduler.json` file in your home directory, the next steps will not work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open up ipython again: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(scheduler_file='scheduler.json')\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch and connect to Jupyter ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From your same session on the login node, run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(scheduler_file='scheduler.json')\n",
    "\n",
    "import socket\n",
    "host = client.run_on_scheduler(socket.gethostname)\n",
    "\n",
    "def start_jlab(dask_scheduler):\n",
    "    import subprocess\n",
    "    proc = subprocess.Popen(['jupyter', 'lab', '--ip', host, '--no-browser'])\n",
    "    dask_scheduler.jlab_proc = proc\n",
    "\n",
    "client.run_on_scheduler(start_jlab)\n",
    "\n",
    "print(\"ssh -N -L 8787:%s:8787 -L 7777:%s:8888 -l gergel us.erdc.hpc.mil\" % (host, host))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: if you are not familiar with using Ipython, the best way to do the previous step is to go into `ipython`, then type `%cpaste` at the prompt - this will allow you to copy the above chunk of code, paste it in as you would normally, then \"enter\", then type `--` to signal that you are done pasting in code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code should print out a statement that looks like this (this is from the Navy Utility Server because the ERDC one was down): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ssh -N -L 8787:stutilm-0001.navo.hpc.mil:8787 -L 7777:stutilm-0001.navo.hpc.mil:8888 -l gergel us.navo.hpc.mil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run this command from your personal computer (not the terminal logged into Cheyenne) to set up SSH-tunnels that will allow you to log into web servers (e.g. Jupyter notebooks) running on your allocation. Afterwards, you should be able to open the following links in your web browser on your computer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, to connect, open up a new terminal window and type that command at the prompt. This should take you to your Utility Server directory in which you launched the job. If not, then your `dask.sh` script may have timed out, or you may need to repeat the above steps (if the connection is slow, sometimes you may need to go through the steps again). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, go to your browser (I think Chrome works best for this) and type: `localhost:7777/tree`. This should give you a password prompt, enter the same password that you set up at the `Enter password:` step above, and you should be on. **IF** that doesn't work, and your password is invalid, then what you need to do is reset the password. I think this issue may be due to a recent change in Jupyter notebook settings. In this case, in a terminal on the Utility Server after activating your virtual environment, type `jupyter notebook password` and follow the prompt to set the password. This will write the password to a new file, titled `/Users/you/.jupyter/jupyter_notebook_config.json`. You need to *delete* the previous hashed password file, `/Users/you/.jupyter/jupyter_notebook_config.py`. This amounts to a password reset, so you then need to delete your job if it's still running, quit your `ipython` notebook session, and then go through the same steps above to launch dask and then connect to it in `ipython`. This should fix the problem (it did for me when I encountered it).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the above steps should work on the AFRL, ERDC and NAVY Utility Servers, as long as you update the logins and go through the same steps on both. I have verified them on the Navy and AFRL machines. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0rc4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
